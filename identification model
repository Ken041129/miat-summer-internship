# =========================
# 方案C：TorchVision骨幹 + 輕量分類頭（貓 vs 狗）
# 上傳你的 Abyssinian（貓）與 American bulldog（狗）圖片，多張皆可
# 不用 !pip、不建資料夾
# =========================

# ==========================================
# 方案C：TorchVision骨幹 + 輕量分類頭（貓 vs 狗）
# 特點：
#   - 支援多骨幹：efficientnet_b0 / efficientnet_b3 / mobilenet_v3_large / resnet50 / vit_b_16
#   - 上傳一次圖片就存到 /content/my_images，之後重跑不用再上傳
#   - 自動依檔名判斷標籤（含 "cat"/"abyssinian" → 貓=0；含 "dog"/"bulldog" → 狗=1）
# ==========================================

from google.colab import files
from PIL import Image
import time, numpy as np
import os, glob, shutil
import torch, torchvision
from torchvision import transforms
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay
import matplotlib.pyplot as plt

# ========= 可調參數 =========
BACKBONE_NAME = "efficientnet_b3"     # 可改成: "efficientnet_b0", "efficientnet_b3", "mobilenet_v3_large", "resnet50", "vit_b_16"
USE_KFOLD = False              # 如果張數多，想更穩定可設 True
N_SPLITS = 5
RANDOM_SEED = 42
# ==========================

torch.set_grad_enabled(False)

# 1) 載入骨幹 & 前處理
def load_backbone(name=BACKBONE_NAME):
    if name == "efficientnet_b0":
        model = torchvision.models.efficientnet_b0(weights="IMAGENET1K_V1")
        feat_dim = model.classifier[1].in_features
        model.classifier = torch.nn.Identity()
    elif name == "efficientnet_b3":
        model = torchvision.models.efficientnet_b3(weights="IMAGENET1K_V1")
        feat_dim = model.classifier[1].in_features
        model.classifier = torch.nn.Identity()
    elif name == "mobilenet_v3_large":
        model = torchvision.models.mobilenet_v3_large(weights="IMAGENET1K_V2")
        feat_dim = model.classifier[0].in_features if hasattr(model.classifier[0],"in_features") else 960
        model.classifier = torch.nn.Identity()
    elif name == "resnet50":
        model = torchvision.models.resnet50(weights="IMAGENET1K_V2")
        feat_dim = model.fc.in_features
        model.fc = torch.nn.Identity()
    elif name == "vit_b_16":
        model = torchvision.models.vit_b_16(weights="IMAGENET1K_V1")
        feat_dim = model.heads.head.in_features
        model.heads.head = torch.nn.Identity()
    else:
        raise ValueError(f"未知骨幹名稱: {name}")

    preprocess = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
    ])
    model.eval()
    return model, preprocess, feat_dim

backbone, preprocess, feat_dim = load_backbone(BACKBONE_NAME)

# 2) 管理 /content/my_images
BASE_DIR = "/content/my_images"
os.makedirs(BASE_DIR, exist_ok=True)

EXTS = ("*.jpg","*.jpeg","*.png","*.webp","*.bmp")
# 把 /content 下殘留的影像搬進 BASE_DIR
root_imgs = []
for ext in EXTS:
    root_imgs.extend(glob.glob(f"/content/{ext}"))
for src in root_imgs:
    dst = os.path.join(BASE_DIR, os.path.basename(src))
    if not os.path.exists(dst):
        try: shutil.move(src, dst)
        except: pass

def list_images():
    files_list = []
    for ext in EXTS:
        files_list.extend(glob.glob(os.path.join(BASE_DIR, ext)))
    return sorted(files_list)

file_names = list_images()
if len(file_names) == 0:
    print("在 /content/my_images 沒找到影像，請選擇圖片（只需上傳一次）：")
    up = files.upload()
    for name, data in up.items():
        with open(os.path.join(BASE_DIR, name), "wb") as f:
            f.write(data)
    file_names = list_images()

print(f"找到的檔案數: {len(file_names)}")
print(file_names[:5])
if len(file_names) < 4:
    print("⚠️ 建議至少 4 張以上（兩類各至少 2 張）才能做訓練/測試。")

# 3) 標籤函式
def label_from_name(name:str) -> int:
    n = name.lower()
    if ("abyssinian" in n) or ("cat" in n):
        return 0   # 貓
    if ("american_bulldog" in n) or ("bulldog" in n) or ("dog" in n):
        return 1   # 狗
    return 1       # 預設狗

labels = [label_from_name(os.path.basename(n)) for n in file_names]

# 4) 特徵抽取 + 推論延遲
X, latencies = [], []
for fname in file_names:
    img = Image.open(fname).convert("RGB")
    timg = preprocess(img).unsqueeze(0)
    t0 = time.time()
    feats = backbone(timg).squeeze(0).cpu().numpy()
    latencies.append((time.time()-t0)*1000.0)
    X.append(feats)

X = np.stack(X)
y = np.array(labels)
print(f"[INFO] 總影像數: {len(y)}, 特徵維度: {X.shape[1]}, 平均單張延遲: {np.mean(latencies):.1f} ms")

# 5) 訓練/評估
def train_eval_simple(X, y, random_state=RANDOM_SEED):
    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.3, stratify=y, random_state=random_state)
    clf = make_pipeline(
        StandardScaler(with_mean=True, with_std=True),
        LogisticRegression(max_iter=500, class_weight="balanced", solver="lbfgs")
    )
    clf.fit(X_tr, y_tr)
    y_pred = clf.predict(X_te)
    print("\n=== 簡單切分成績（貓=0, 狗=1）===")
    print(classification_report(y_te, y_pred, digits=4))
    print("混淆矩陣：\n", confusion_matrix(y_te, y_pred))
    try:
        y_prob = clf.predict_proba(X_te)[:,1]
        auc = roc_auc_score(y_te, y_prob)
        print(f"ROC AUC: {auc:.4f}")
        RocCurveDisplay.from_predictions(y_te, y_prob)
        plt.title("ROC Curve")
        plt.show()
    except: pass
    return clf

def train_eval_kfold(X, y, n_splits=N_SPLITS, random_state=RANDOM_SEED):
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    aucs = []
    for i,(tr_idx,te_idx) in enumerate(skf.split(X, y),1):
        clf = make_pipeline(
            StandardScaler(with_mean=True, with_std=True),
            LogisticRegression(max_iter=500, class_weight="balanced", solver="lbfgs")
        )
        clf.fit(X[tr_idx], y[tr_idx])
        y_pred = clf.predict(X[te_idx])
        print(f"\n=== 第 {i} 折 ===")
        print(classification_report(y[te_idx], y_pred, digits=4))
        try:
            y_prob = clf.predict_proba(X[te_idx])[:,1]
            auc = roc_auc_score(y[te_idx], y_prob); aucs.append(auc)
            print(f"AUC: {auc:.4f}")
        except: pass
    if aucs: print(f"\nK-fold 平均 AUC: {np.mean(aucs):.4f} (+/- {np.std(aucs):.4f})")
    return clf.fit(X,y)  # 全資料重訓

if USE_KFOLD and len(np.unique(y))==2 and len(y)>=N_SPLITS:
    clf = train_eval_kfold(X, y)
else:
    clf = train_eval_simple(X, y)

print(f"平均骨幹推論延遲（ms/張）: {np.mean(latencies):.1f}")

# 6) 推論函式
def predict_images(pil_images_or_paths, model=backbone, preproc=preprocess, clf_pipeline=clf):
    def _to_pil(x):
        if isinstance(x, Image.Image): return x.convert("RGB")
        if isinstance(x, str): return Image.open(x).convert("RGB")
        raise ValueError("Unsupported input type")

    outs = []
    inputs = pil_images_or_paths if isinstance(pil_images_or_paths,(list,tuple)) else [pil_images_or_paths]
    for item in inputs:
        img = _to_pil(item)
        t = preproc(img).unsqueeze(0)
        with torch.no_grad():
            feat = model(t).squeeze(0).cpu().numpy().reshape(1,-1)
        prob = clf_pipeline.predict_proba(feat)[0,1]
        lbl = "dog(狗)" if prob>=0.5 else "cat(貓)"
        outs.append((lbl, float(prob)))
    return outs

print("\n✅ 已建立 predict_images()，可直接傳路徑或 PIL.Image 做單張/多張推論")
